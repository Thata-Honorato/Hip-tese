{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "\n\nOl\u00e1 estudante!\n\nMe chamo Rafael Meirelles e irei revisar o seu projeto hoje e em eventuais futuras submiss\u00f5es at\u00e9 que ele cumpra todos os requisitos para o aceite.\nConte comigo nessa jornada e n\u00e3o se preocupe se precisar ajustar alguns detalhes, \u00e9 parte do processo e fundamental para que voc\u00ea exercite os conceitos que vem aprendendo e assim melhore a qualidade dos seus c\u00f3digos e an\u00e1lises.\n\n**Pe\u00e7o que mantenha e n\u00e3o altereos coment\u00e1rios que eu fizer por aqui para que possamos nos localizar posteriormente, ok?**\n\nMais uma coisa, vamos utilizar um c\u00f3digo de cores para voc\u00ea entender os meus feedbacks no seu notebook. Funciona assim:\n\n\n<div class=\"alert alert-danger\">\n<strong>Vermelho</strong>\n\nErro que precisa ser consertado, caso contr\u00e1rio, seu projeto n\u00e3o pode ser aceito\n\n</div>\n\n<div class=\"alert alert-warning\">\n<strong>Amarelo</strong>\n\nAlerta de um erro n\u00e3o cr\u00edtco, mas que pode ser corrigido para melhoria geral no seu c\u00f3digo/an\u00e1lise\n\n</div>\n\n<div class=\"alert alert-success\">\n<strong>Verde</strong>\n\nElogios\n</div>\n\n<div class=\"alert alert-info\">\n<strong>Coment\u00e1rio do estudante</strong>\n\nUse uma caixa azul como essa para eventuais coment\u00e1rios que voc\u00ea gostaria de fazer para mim.\n</div>\n\n\n\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": true}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": true}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": true}, "outputs": [], "source": ""}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-danger\">\n<strong>Coment\u00e1rio do revisor v1</strong>\n\nThata, devemos ter apenas uma importa\u00e7\u00e3o de dados no projeto e todos os passos posteriores devem ser feitos sobre esse objeto. Estou devolvendo o projeto para esse ajuste e posteriormente seguimos com a revis\u00e3o.\n</div>\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-danger\">\n<strong>Coment\u00e1rio do revisor v2</strong>\n\nEstamos no caminho certo com essa vers\u00e3o, mas retocar os pontos indicados abaixo nos far\u00e1 chegar em um resultado ainda mais incr\u00edvel.\n    \nConte comigo para ajud\u00e1-lo (a) em qualquer quest\u00e3o que possa vir a ter! Lembre-se de usar as caixas azuis para se comunicar comigo.\n    \nAt\u00e9 breve.\n</div>\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-danger\">\n<strong>Coment\u00e1rio do revisor v3</strong>\n\nAvan\u00e7amos bastante com os ajustes, mas ainda temos alguns pontos pendentes. Procure por 'v3' para encontr\u00e1-los com mais facilidade.\n\nEstamos quase l\u00e1! Vamos juntos at\u00e9 o fim.\n</div>\n\n"}, {"cell_type": "markdown", "metadata": {"id": "E0vqbgi9ay0H"}, "source": "# Se liga na m\u00fasica"}, {"cell_type": "markdown", "metadata": {"id": "fhq_eyov_Zcs"}, "source": "# Conte\u00fado <a id='back'></a>\n\n* [Introdu\u00e7\u00e3o](#intro)\n* [Etapa 1. Vis\u00e3o geral dos dados](#data_review)\n    * [Conclus\u00f5es](#data_review_conclusions)\n* [Etapa 2. Pr\u00e9-processamento de dados](#data_preprocessing)\n    * [2.1 Estilo do cabe\u00e7alho](#header_style)\n    * [2.2 Valores ausentes](#missing_values)\n    * [2.3 Duplicados](#duplicates)\n    * [2.4 Conclus\u00f5es](#data_preprocessing_conclusions)\n* [Etapa 3. Teste da hip\u00f3tese](#hypothesis)\n    * [3.1 Hip\u00f3tese 1: atividade dos usu\u00e1rios nas duas cidades](#activity)\n* [Conclus\u00f5es](#end)"}, {"cell_type": "markdown", "metadata": {"id": "VUC88oWjTJw2"}, "source": "## Introdu\u00e7\u00e3o <a id='intro'></a>\nO trabalho de um analista \u00e9 analisar dados para obter percep\u00e7\u00f5es valiosas dos dados e tomar decis\u00f5es fundamentadas neles. Esse processo consiste em v\u00e1rias etapas, como vis\u00e3o geral dos dados, pr\u00e9-processamento dos dados e testes de hip\u00f3teses.\n\nSempre que fazemos uma pesquisa, precisamos formular uma hip\u00f3tese que depois poderemos testar. \u00c0s vezes n\u00f3s aceitamos essas hip\u00f3teses; outras vezes, n\u00f3s as rejeitamos. Para fazer as escolhas certas, um neg\u00f3cio deve ser capaz de entender se est\u00e1 fazendo as suposi\u00e7\u00f5es certas ou n\u00e3o.\n\nNeste projeto, voc\u00ea vai comparar as prefer\u00eancias musicais dos habitantes de Springfild e Shelbyville. Voc\u00ea vai estudar os dados de um servi\u00e7o de streaming de m\u00fasica online para testar a hip\u00f3tese apresentada abaixo e comparar o comportamento dos usu\u00e1rios dessas duas cidades.\n\n### Objetivo:\nTeste a hip\u00f3tese:\n1. A atividade dos usu\u00e1rios \u00e9 diferente dependendo do dia da semana e da cidade.\n\n\n### Etapas\nOs dados sobre o comportamento do usu\u00e1rio s\u00e3o armazenados no arquivo `/datasets/music_project_en.csv`. N\u00e3o h\u00e1 informa\u00e7\u00f5es sobre a qualidade dos dados, ent\u00e3o ser\u00e1 necess\u00e1rio examin\u00e1-los antes de testar a hip\u00f3tese.\n\nPrimeiro, voc\u00ea avaliar\u00e1 a qualidade dos dados e ver\u00e1 se seus problemas s\u00e3o significativos. Depois, durante o pr\u00e9-processamento dos dados, voc\u00ea tentar\u00e1 tratar dos problemas mais cr\u00edticos.\n\nO seu projeto consistir\u00e1 em tr\u00eas etapas:\n 1. Vis\u00e3o geral dos dados\n 2. Pr\u00e9-processamento de dados\n 3. Teste da hip\u00f3tese\n\n\n\n\n\n\n"}, {"cell_type": "markdown", "metadata": {"id": "hDt6pg-Rw-1U"}, "source": "[Voltar ao \u00cdndice](#back)"}, {"cell_type": "markdown", "metadata": {"id": "Ml1hmfXC_Zcs"}, "source": "## Etapa 1. Vis\u00e3o geral dos dados <a id='data_review'></a>\n\nAbra os dados e examine-os."}, {"cell_type": "markdown", "metadata": {"id": "57eAOGIz_Zcs"}, "source": "Voc\u00ea precisar\u00e1 da `pandas`, ent\u00e3o, importe-a."}, {"cell_type": "code", "execution_count": 3, "metadata": {"id": "AXN7PHPN_Zcs", "trusted": true}, "outputs": [], "source": "import pandas as pd # importando pandas\n"}, {"cell_type": "markdown", "metadata": {"id": "SG23P8tt_Zcs"}, "source": "Leia o arquivo `music_project_en.csv` da pasta `/datasets/` e salve-o na vari\u00e1vel `df`:"}, {"cell_type": "code", "execution_count": 4, "metadata": {"id": "fFVu7vqh_Zct", "trusted": true}, "outputs": [], "source": "df = pd.read_csv('/datasets/music_project_en.csv')\n\n\n# lendo o arquivo e armazenando em df\n"}, {"cell_type": "markdown", "metadata": {"id": "rDoOMd3uTqnZ"}, "source": "Imprima as primeiras 10 linhas da tabela:"}, {"cell_type": "code", "execution_count": 5, "metadata": {"id": "oWTVX3gW_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "     userID                        Track            artist   genre  \\\n0  FFB692EC            Kamigata To Boots  The Mass Missile    rock   \n1  55204538  Delayed Because of Accident  Andreas R\u00f6nnberg    rock   \n2    20EC38            Funicul\u00ec funicul\u00e0       Mario Lanza     pop   \n3  A3DD03C9        Dragons in the Sunset        Fire + Ice    folk   \n4  E2DC1FAE                  Soul People        Space Echo   dance   \n5  842029A1                       Chains          Obladaet  rusrap   \n6  4CB90AA5                         True      Roman Messer   dance   \n7  F03E1C1F             Feeling This Way   Polina Griffith   dance   \n8  8FA1D3BE                     L\u2019estate       Julia Dalia  ruspop   \n9  E772D5C0                    Pessimist               NaN   dance   \n\n        City        time        Day  \n0  Shelbyville  20:28:33  Wednesday  \n1  Springfield  14:07:09     Friday  \n2  Shelbyville  20:58:07  Wednesday  \n3  Shelbyville  08:37:09     Monday  \n4  Springfield  08:34:34     Monday  \n5  Shelbyville  13:09:41     Friday  \n6  Springfield  13:00:07  Wednesday  \n7  Springfield  20:47:49  Wednesday  \n8  Springfield  09:17:40     Friday  \n9  Shelbyville  21:20:49  Wednesday  \n"}], "source": "\nprint(df.head(10))# obtenha as 10 primeiras 10 linhas da tabela df\n"}, {"cell_type": "markdown", "metadata": {"id": "EO73Kwic_Zct"}, "source": "Obtenha informa\u00e7\u00f5es gerais sobre a tabela usando um comando. Voc\u00ea conhece o m\u00e9todo para exibir informa\u00e7\u00f5es gerais que precisamos obter."}, {"cell_type": "code", "execution_count": 14, "metadata": {"id": "DSf2kIb-_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 65079 entries, 0 to 65078\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0     userID  65079 non-null  object\n 1   Track     63736 non-null  object\n 2   artist    57512 non-null  object\n 3   genre     63881 non-null  object\n 4     City    65079 non-null  object\n 5   time      65079 non-null  object\n 6   Day       65079 non-null  object\ndtypes: object(7)\nmemory usage: 3.5+ MB\nNone\n"}], "source": "print(df.info())# obtendo informa\u00e7\u00f5es gerais sobre os nossos dados\n"}, {"cell_type": "markdown", "metadata": {"id": "TaQ2Iwbr_Zct"}, "source": "Aqui est\u00e3o as nossas observa\u00e7\u00f5es sobre a tabela. Ela cont\u00e9m sete colunas. Elas armazenam o mesmo tipo de dado: `object`.\n\nDe acordo com a documenta\u00e7\u00e3o:\n- `' userID'` \u2014 identifica\u00e7\u00e3o do usu\u00e1rio\n- `'Track'` \u2014 t\u00edtulo da m\u00fasica\n- `'artist'` \u2014 nome do artista\n- `'genre'` \u2014 g\u00eanero da m\u00fasica\n- `'City'` \u2014 cidade do usu\u00e1rio\n- `'time'` \u2014 o tempo exato que a m\u00fasica foi reproduzida\n- `'Day'` \u2014 dia da semana\n\nPodemos ver tr\u00eas problemas de estilo nos cabe\u00e7alhos da tabela:\n1. Alguns cabe\u00e7alhos s\u00e3o escritos em letras mai\u00fasculas, outros est\u00e3o em min\u00fasculas.\n2. Alguns cabe\u00e7alhos cont\u00eam espa\u00e7os.\n3. `Detecte o problema e o descreva aqui`.\n   \n   Duplicatas\nOs dados com cabe\u00e7alho bagun\u00e7ado podem dificultar o entendimento das informa\u00e7\u00f5es\nmuitas vezes pode dar erro ao preencher com os c\u00f3ds, visto que a escrita ficar\u00e1 diferente \n\n"}, {"cell_type": "markdown", "metadata": {"id": "MCB6-dXG_Zct"}, "source": "### Escreva suas observa\u00e7\u00f5es. Aqui est\u00e3o algumas perguntas que podem ajudar: <a id='data_review_conclusions'></a>\n\n`1.   Que tipo de dados temos nas linhas? E como podemos entender as colunas?` Dados mais superficiais que n\u00e3o demostram muito al\u00e9m de especificidades de artistas e m\u00fasicas. \n\n`2.   Esses dados s\u00e3o suficientes para responder \u00e0 nossa hip\u00f3tese ou precisamos de mais dados?` N\u00e3o s\u00e3o suficientes, tem muitos valores ausentes para essa pesquisa.\n\n`3.   Voc\u00ea notou algum problema nos dados, como valores ausentes, duplicados ou tipos de dados errados` Valores ausentes podem dificultar \u00e0 analise, al\u00e9m disso city, time e day est\u00e3o com valores iguais, o que pode ser uma duplicata "}, {"cell_type": "markdown", "metadata": {"id": "3eL__vcwViOi"}, "source": "[Voltar ao \u00cdndice](#back)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<strong>Coment\u00e1rio do revisor v1</strong>\n\nBom trabalho com a introdu\u00e7\u00e3o!\n\n</div>\n\n"}, {"cell_type": "markdown", "metadata": {"id": "SjYF6Ub9_Zct"}, "source": "## Etapa 2. Pr\u00e9-processamento de dados <a id='data_preprocessing'></a>\n\nO objetivo aqui \u00e9 preparar os dados para a an\u00e1lise.\nO primeiro passo \u00e9 resolver todos os problemas com o cabe\u00e7alho. E ent\u00e3o podemos passar para os valores ausentes e duplicados. Vamos come\u00e7ar.\n\nCorrija a formata\u00e7\u00e3o nos cabe\u00e7alhos da tabela.\n"}, {"cell_type": "markdown", "metadata": {"id": "dIaKXr29_Zct"}, "source": "### Estilo do cabe\u00e7alho <a id='header_style'></a>\nImprima os cabe\u00e7alhos da tabela (os nomes das colunas):"}, {"cell_type": "code", "execution_count": 15, "metadata": {"id": "oKOTdF_Q_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n"}], "source": "print(df.columns)"}, {"cell_type": "markdown", "metadata": {"id": "zj5534cv_Zct"}, "source": "Mude os cabe\u00e7alhos da tabela conforme as boas pr\u00e1ticas de estilo:\n* Todos os caracteres precisam estar com letras min\u00fasculas\n* Exclua espa\u00e7os\n* Se o nome tiver v\u00e1rias palavras, use snake_case"}, {"cell_type": "markdown", "metadata": {"id": "Xu0zkfe5zNJe"}, "source": "Anteriormente, voc\u00ea aprendeu sobre uma maneira automatizada de renomear colunas. Vamos us\u00e1-la agora. Use o ciclo for para percorrer os nomes das colunas e transformar todos os caracteres em letras min\u00fasculas. Ap\u00f3s fazer isso, imprima os cabe\u00e7alhos da tabela novamente:"}, {"cell_type": "code", "execution_count": 16, "metadata": {"id": "6I_RwwMhzM4e", "trusted": true}, "outputs": [], "source": "\n    \n\ndf.columns = df.columns.str.lower().str.replace('   ', '_')\n\n\n    # Percorrendo os cabe\u00e7alhos e convertendo tudo em min\u00fasculos\n"}, {"cell_type": "markdown", "metadata": {"id": "pweIRxjSzPYW"}, "source": "Agora, usando a mesma abordagem, exclua os espa\u00e7os no in\u00edcio e no final de cada nome de coluna e imprima os nomes das colunas novamente:"}, {"cell_type": "code", "execution_count": 17, "metadata": {"id": "vVQXbFyJzSYl", "trusted": true}, "outputs": [], "source": "\n    \n\ndf.columns = df.columns.str.strip()# Percorrendo os cabe\u00e7alhos e removendo os espa\u00e7os\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-danger\">\n<strong>Coment\u00e1rio do revisor v1</strong>\n\nThata, devemos ter apenas uma importa\u00e7\u00e3o de dados no projeto e todos os passos posteriores devem ser feitos sobre esse objeto. Estou devolvendo o projeto para esse ajuste e posteriormente seguimos com a revis\u00e3o.\n</div>\n\n"}, {"cell_type": "markdown", "metadata": {"id": "yCb8MW1JzURd"}, "source": "Precisamos aplicar a regra de sublinhado no lugar de espa\u00e7o \u00e0 coluna `userid`. Deveria ser `user_id`. Renomeie essa coluna e imprima os nomes de todas as colunas quando terminar."}, {"cell_type": "code", "execution_count": 6, "metadata": {"id": "ISlFqs5y_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "        user_id                              Track            artist  \\\n0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n1      55204538        Delayed Because of Accident  Andreas R\u00f6nnberg   \n2        20EC38                  Funicul\u00ec funicul\u00e0       Mario Lanza   \n3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n4      E2DC1FAE                        Soul People        Space Echo   \n...         ...                                ...               ...   \n65074  729CBB09                            My Name            McLean   \n65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n65076  C5E3A0D5                          Jalopiina               NaN   \n65077  321D0506                      Freight Train     Chas McDevitt   \n65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n\n            genre       City        time        Day  \n0            rock  Shelbyville  20:28:33  Wednesday  \n1            rock  Springfield  14:07:09     Friday  \n2             pop  Shelbyville  20:58:07  Wednesday  \n3            folk  Shelbyville  08:37:09     Monday  \n4           dance  Springfield  08:34:34     Monday  \n...           ...          ...       ...        ...  \n65074         rnb  Springfield  13:32:28  Wednesday  \n65075         hip  Shelbyville  10:00:00     Monday  \n65076  industrial  Springfield  20:09:26     Friday  \n65077        rock  Springfield  21:43:59     Friday  \n65078     country  Springfield  21:59:46     Friday  \n\n[65079 rows x 7 columns]\n"}], "source": "df= df.rename(columns= {'  userID': 'user_id'})\n\nprint(df)# Renomeando a coluna \"userid\"\n"}, {"cell_type": "markdown", "metadata": {"id": "1dqbh00J_Zct"}, "source": "Verifique o resultado. Imprima os cabe\u00e7alhos novamente:"}, {"cell_type": "code", "execution_count": 7, "metadata": {"id": "d4NOAmTW_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['user_id', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n"}], "source": " \n\nprint(df.columns)# verificando o resultado: a lista de cabe\u00e7alhos\n"}, {"cell_type": "code", "execution_count": 8, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['user_id', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n"}], "source": "print (df.columns)"}, {"cell_type": "markdown", "metadata": {}, "source": "\n<div class=\"alert alert-danger\">\n<strong>Coment\u00e1rio do revisor v2</strong>\n\nAinda h\u00e1 problemas com os nomes das colunas.\n</div>\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<strong>Coment\u00e1rio do revisor v3</strong>\n\nValeu pelo ajuste!\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "5ISfbcfY_Zct"}, "source": "### Valores Ausentes <a id='missing_values'></a>\n Primeiro, encontre a quantidade de valores ausentes na tabela. Voc\u00ea precisa usar dois m\u00e9todos em sequ\u00eancia para obter o n\u00famero de valores ausentes."}, {"cell_type": "code", "execution_count": 21, "metadata": {"id": "RskX29qr_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "         userid                              track            artist  \\\n0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n1      55204538        Delayed Because of Accident  Andreas R\u00f6nnberg   \n2        20EC38                  Funicul\u00ec funicul\u00e0       Mario Lanza   \n3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n4      E2DC1FAE                        Soul People        Space Echo   \n...         ...                                ...               ...   \n65074  729CBB09                            My Name            McLean   \n65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n65076  C5E3A0D5                          Jalopiina               NaN   \n65077  321D0506                      Freight Train     Chas McDevitt   \n65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n\n            genre         city      time        day  \n0            rock  Shelbyville  20:28:33  Wednesday  \n1            rock  Springfield  14:07:09     Friday  \n2             pop  Shelbyville  20:58:07  Wednesday  \n3            folk  Shelbyville  08:37:09     Monday  \n4           dance  Springfield  08:34:34     Monday  \n...           ...          ...       ...        ...  \n65074         rnb  Springfield  13:32:28  Wednesday  \n65075         hip  Shelbyville  10:00:00     Monday  \n65076  industrial  Springfield  20:09:26     Friday  \n65077        rock  Springfield  21:43:59     Friday  \n65078     country  Springfield  21:59:46     Friday  \n\n[65079 rows x 7 columns]\n"}], "source": "\nvalores_ausentes = df.isna().sum()\n\nprint(df)# calculando o n\u00famero de valores ausentes\n"}, {"cell_type": "markdown", "metadata": {"id": "qubhgnlO_Zct"}, "source": "Nem todos os valores ausentes afetam a pesquisa. Por exemplo, os valores ausentes em `track` e `artist` n\u00e3o s\u00e3o cr\u00edticos. Voc\u00ea pode simplesmente substitu\u00ed-los por valores padr\u00e3o, como a string `'unknown'`.\n\nMas valores ausentes em `'genre'` podem afetar a compara\u00e7\u00e3o de prefer\u00eancias musicais de Springfield e Shelbyville. Na vida real, seria \u00fatil descobrir as raz\u00f5es pelas quais os dados est\u00e3o ausentes e tentar corrigi-los. Mas n\u00f3s n\u00e3o temos essa possibilidade neste projeto. Ent\u00e3o, voc\u00ea ter\u00e1 que:\n* Preencha esses valores ausentes com um valor padr\u00e3o\n* Avalie em que medida os valores ausentes podem afetar sua an\u00e1lise"}, {"cell_type": "markdown", "metadata": {"id": "fSv2laPA_Zct"}, "source": "Substitua os valores ausentes nas colunas `'track'`, `'artist'` e `'genre'` pela string `'unknown'`. Como mostramos nas li\u00e7\u00f5es anteriores, a melhor maneira de fazer isso \u00e9 criar uma lista para armazenar os nomes das colunas nas quais precisamos fazer a substitui\u00e7\u00e3o. Em seguida, use essa lista e percorra as colunas nas quais a substitui\u00e7\u00e3o seja necess\u00e1ria e fa\u00e7a a substitui\u00e7\u00e3o."}, {"cell_type": "code", "execution_count": 20, "metadata": {"id": "KplB5qWs_Zct", "scrolled": true, "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "user_id     0\nTrack       0\nartist      0\ngenre       0\n  City      0\ntime        0\nDay         0\ndtype: int64\n    user_id                        Track            artist  genre  \\\n0  FFB692EC            Kamigata To Boots  The Mass Missile   rock   \n1  55204538  Delayed Because of Accident  Andreas R\u00f6nnberg   rock   \n2    20EC38            Funicul\u00ec funicul\u00e0       Mario Lanza    pop   \n3  A3DD03C9        Dragons in the Sunset        Fire + Ice   folk   \n4  E2DC1FAE                  Soul People        Space Echo  dance   \n\n        City        time        Day  \n0  Shelbyville  20:28:33  Wednesday  \n1  Springfield  14:07:09     Friday  \n2  Shelbyville  20:58:07  Wednesday  \n3  Shelbyville  08:37:09     Monday  \n4  Springfield  08:34:34     Monday  \n"}], "source": "\n\n\ncolumns_to_fill = ['Track', 'artist', 'genre']\n\n\nfor column in columns_to_fill:\n    if column in df.columns:  \n        df[column] = df[column].fillna('unknown')\n\n\nprint(df.isna().sum())\n\n\nprint(df.head())\n\n\n# percorrendo os cabe\u00e7alhos e substituindo valores ausentes por 'unknown'\n"}, {"cell_type": "markdown", "metadata": {"id": "Ilsm-MZo_Zct"}, "source": "Agora verifique o resultado para ter certeza de que o conjunto de dados n\u00e3o contenha valores ausentes ap\u00f3s a substitui\u00e7\u00e3o. Para fazer isso, conte os valores ausentes novamente."}, {"cell_type": "code", "execution_count": 19, "metadata": {"id": "Tq4nYRX4_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "        user_id                              Track            artist  \\\n0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n1      55204538        Delayed Because of Accident  Andreas R\u00f6nnberg   \n2        20EC38                  Funicul\u00ec funicul\u00e0       Mario Lanza   \n3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n4      E2DC1FAE                        Soul People        Space Echo   \n...         ...                                ...               ...   \n65074  729CBB09                            My Name            McLean   \n65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n65076  C5E3A0D5                          Jalopiina           unknown   \n65077  321D0506                      Freight Train     Chas McDevitt   \n65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n\n            genre       City        time        Day  \n0            rock  Shelbyville  20:28:33  Wednesday  \n1            rock  Springfield  14:07:09     Friday  \n2             pop  Shelbyville  20:58:07  Wednesday  \n3            folk  Shelbyville  08:37:09     Monday  \n4           dance  Springfield  08:34:34     Monday  \n...           ...          ...       ...        ...  \n65074         rnb  Springfield  13:32:28  Wednesday  \n65075         hip  Shelbyville  10:00:00     Monday  \n65076  industrial  Springfield  20:09:26     Friday  \n65077        rock  Springfield  21:43:59     Friday  \n65078     country  Springfield  21:59:46     Friday  \n\n[65079 rows x 7 columns]\n"}], "source": "\n\n\nvalores_ausentes=df.isnull().sum\n\nprint (df)# contando os valores ausentes\n"}, {"cell_type": "markdown", "metadata": {"id": "74ZIBmq9VrsK"}, "source": "[Voltar ao \u00cdndice](#back)"}, {"cell_type": "markdown", "metadata": {}, "source": "\n<div class=\"alert alert-success\">\n<strong>Coment\u00e1rio do revisor v2</strong>\n\nValores ausentes tratados. (Cuidado ao corrigiro nome das colunas para alterar aqui tamb\u00e9m).\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "BWKRtBJ3_Zct"}, "source": "### Duplicados <a id='duplicates'></a>\nEncontre o n\u00famero de duplicados expl\u00edcitos na tabela. Lembre-se de que voc\u00ea precisa aplicar dois m\u00e9todos em sequ\u00eancia para obter o n\u00famero de duplicados expl\u00edcitos."}, {"cell_type": "code", "execution_count": 24, "metadata": {"id": "36eES_S0_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "         userid                              track            artist  \\\n0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n1      55204538        Delayed Because of Accident  Andreas R\u00f6nnberg   \n2        20EC38                  Funicul\u00ec funicul\u00e0       Mario Lanza   \n3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n4      E2DC1FAE                        Soul People        Space Echo   \n...         ...                                ...               ...   \n65074  729CBB09                            My Name            McLean   \n65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n65076  C5E3A0D5                          Jalopiina           unknown   \n65077  321D0506                      Freight Train     Chas McDevitt   \n65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n\n            genre         city      time        day  \n0            rock  Shelbyville  20:28:33  Wednesday  \n1            rock  Springfield  14:07:09     Friday  \n2             pop  Shelbyville  20:58:07  Wednesday  \n3            folk  Shelbyville  08:37:09     Monday  \n4           dance  Springfield  08:34:34     Monday  \n...           ...          ...       ...        ...  \n65074         rnb  Springfield  13:32:28  Wednesday  \n65075         hip  Shelbyville  10:00:00     Monday  \n65076  industrial  Springfield  20:09:26     Friday  \n65077        rock  Springfield  21:43:59     Friday  \n65078     country  Springfield  21:59:46     Friday  \n\n[65079 rows x 7 columns]\n"}], "source": "\n\n\nduplicates = df.duplicated().sum()\n\nprint(df)# contando duplicados expl\u00edcitos\n"}, {"cell_type": "markdown", "metadata": {"id": "Ot25h6XR_Zct"}, "source": "Agora descarte todos os duplicados. Para fazer isso, chame o m\u00e9todo que faz exatamente isso."}, {"cell_type": "code", "execution_count": 25, "metadata": {"id": "exFHq6tt_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "         userid                              track            artist  \\\n0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n1      55204538        Delayed Because of Accident  Andreas R\u00f6nnberg   \n2        20EC38                  Funicul\u00ec funicul\u00e0       Mario Lanza   \n3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n4      E2DC1FAE                        Soul People        Space Echo   \n...         ...                                ...               ...   \n65074  729CBB09                            My Name            McLean   \n65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n65076  C5E3A0D5                          Jalopiina           unknown   \n65077  321D0506                      Freight Train     Chas McDevitt   \n65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n\n            genre         city      time        day  \n0            rock  Shelbyville  20:28:33  Wednesday  \n1            rock  Springfield  14:07:09     Friday  \n2             pop  Shelbyville  20:58:07  Wednesday  \n3            folk  Shelbyville  08:37:09     Monday  \n4           dance  Springfield  08:34:34     Monday  \n...           ...          ...       ...        ...  \n65074         rnb  Springfield  13:32:28  Wednesday  \n65075         hip  Shelbyville  10:00:00     Monday  \n65076  industrial  Springfield  20:09:26     Friday  \n65077        rock  Springfield  21:43:59     Friday  \n65078     country  Springfield  21:59:46     Friday  \n\n[61253 rows x 7 columns]\n"}], "source": "\n\n\n\n\ndf = df.drop_duplicates()\n\n\nprint(df)# removendo duplicados expl\u00edcitos\n"}, {"cell_type": "markdown", "metadata": {"id": "Im2YwBEG_Zct"}, "source": "Agora vamos verificar se descartamos todos os duplicados. Conte duplicados expl\u00edcitos mais uma vez para ter certeza de que voc\u00ea removeu todos eles:"}, {"cell_type": "code", "execution_count": 26, "metadata": {"id": "-8PuNWQ0_Zct", "scrolled": true, "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "         userid                              track            artist  \\\n0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n1      55204538        Delayed Because of Accident  Andreas R\u00f6nnberg   \n2        20EC38                  Funicul\u00ec funicul\u00e0       Mario Lanza   \n3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n4      E2DC1FAE                        Soul People        Space Echo   \n...         ...                                ...               ...   \n61248  729CBB09                            My Name            McLean   \n61249  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n61250  C5E3A0D5                          Jalopiina           unknown   \n61251  321D0506                      Freight Train     Chas McDevitt   \n61252  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n\n            genre         city      time        day  \n0            rock  Shelbyville  20:28:33  Wednesday  \n1            rock  Springfield  14:07:09     Friday  \n2             pop  Shelbyville  20:58:07  Wednesday  \n3            folk  Shelbyville  08:37:09     Monday  \n4           dance  Springfield  08:34:34     Monday  \n...           ...          ...       ...        ...  \n61248         rnb  Springfield  13:32:28  Wednesday  \n61249         hip  Shelbyville  10:00:00     Monday  \n61250  industrial  Springfield  20:09:26     Friday  \n61251        rock  Springfield  21:43:59     Friday  \n61252     country  Springfield  21:59:46     Friday  \n\n[61253 rows x 7 columns]\n"}], "source": "df = df.reset_index(drop=True)\n\ndf = df.drop_duplicates()\n\n\nprint(df)# verificando duplicados novamente\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "\n<div class=\"alert alert-danger\">\n<strong>Coment\u00e1rio do revisor v2</strong>\n\nAqui vale a pena utilizar o .reset_index(drop=True) para garantir que n\u00e3o teremos problemas com a ordem das observa\u00e7\u00f5es ap\u00f3s removermos os duplicados:\n    \nAo remover duplicatas, o \u00edndice do DataFrame pode ficar desorganizado. Isso significa que voc\u00ea pode acabar com lacunas no \u00edndice ou com \u00edndices que n\u00e3o est\u00e3o mais em ordem sequencial. O m\u00e9todo reset_index() redefine o \u00edndice do DataFrame, garantindo que ele esteja organizado novamente em uma sequ\u00eancia num\u00e9rica cont\u00ednua.\n</div>\n\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<strong>Coment\u00e1rio do revisor v3</strong>\n\nValeu pelo ajuste!\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "QlFBsxAr_Zct"}, "source": "Agora queremos nos livrar dos duplicados impl\u00edcitos na coluna `genre`. Por exemplo, o nome de um g\u00eanero pode ser escrito de maneiras diferentes. Alguns erros afetar\u00e3o tamb\u00e9m o resultado."}, {"cell_type": "markdown", "metadata": {"id": "eSjWwsOh_Zct"}, "source": "Para fazer isso, vamos come\u00e7ar imprimindo uma lista de nomes de g\u00eanero \u00fanicos, ordenados em ordem alfab\u00e9tica: Para fazer isso:\n* Extraia a coluna `genre` do DataFrame\n* Chame o m\u00e9todo que retornar\u00e1 todos os valores \u00fanicos na coluna extra\u00edda\n"}, {"cell_type": "code", "execution_count": 27, "metadata": {"id": "JIUcqzZN_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "0\n"}], "source": "\n\n\n\npop = df[df['genre'] == \"pop\"].copy() # tive que criar uma c\u00f3pia, pois o DataFrame n\u00e3o recebia as altera\u00e7\u00f5es \n\n\npop.drop_duplicates(inplace=True)\n\n\nprint(pop.duplicated().sum())# visualizando nomes de g\u00eaneros \u00fanicos"}, {"cell_type": "markdown", "metadata": {"id": "qej-Qmuo_Zct"}, "source": "Olhe a lista e encontre duplicados impl\u00edcitos do g\u00eanero `hiphop`. Esses podem ser nomes escritos incorretamente, ou nomes alternativos para o mesmo g\u00eanero.\n\nVoc\u00ea ver\u00e1 os seguintes duplicados impl\u00edcitos:\n* `hip`\n* `hop`\n* `hip-hop`\n\nPara se livrar deles, crie uma fun\u00e7\u00e3o `replace_wrong_genres()` com dois par\u00e2metros:\n* `wrong_genres=` \u2014 essa \u00e9 uma lista que cont\u00e9m todos os valores que voc\u00ea precisa substituir\n* `correct_genre=` \u2014 essa \u00e9 uma string que voc\u00ea vai usar para a substitui\u00e7\u00e3o\n\nComo resultado, a fun\u00e7\u00e3o deve corrigir os nomes na coluna `'genre'` da tabela `df`, isto \u00e9, substituindo cada valor da lista `wrong_genres` por valores de `correct_genre`.\n\nDentro do corpo da fun\u00e7\u00e3o, use um ciclo `'for'` para percorrer a lista de g\u00eaneros errados, extrair a coluna `'genre'` e aplicar o m\u00e9todo `replace` para fazer as corre\u00e7\u00f5es."}, {"cell_type": "code", "execution_count": 28, "metadata": {"id": "ErNDkmns_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n 'unknown' 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock'\n 'latin' 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental'\n 'rusrock' 'dnb' 't\u00fcrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n 'disco' 'religious' 'drum' 'extrememetal' 't\u00fcrk\u00e7e' 'experimental' 'easy'\n 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n 'stonerrock' 'industrial' 'funk' 'middle' 'vari\u00e9t\u00e9' 'other' 'adult'\n 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n 'africa' 'audiobook' 'jewish' 's\u00e4ngerportrait' 'deutschrock' 'eastern'\n 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n 'brazilian' '\u00ef\u00ee\u00ef' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n 'synthpop' 'rave' 'franz\u00f6sisch' 'quebecois' 'speech' 'soulful' 'jam'\n 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n 'ax\u00e9' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forr\u00f3' 'dirty'\n 'regional']\n"}], "source": "\n\n\ndef replace_wrong_genres(wrong_genres, correct_genre):\n    for genre in wrong_genres:\n        df['genre'] = df['genre'].replace(genre, correct_genre)\n\n\nwrong_genres = ['hip', 'hop', 'hip-hop']\n\n\ncorrect_genre = 'hiphop'\n\n\nreplace_wrong_genres(wrong_genres, correct_genre)\n\n\nprint(df['genre'].unique())# fun\u00e7\u00e3o para substituir duplicados impl\u00edcitos\n"}, {"cell_type": "markdown", "metadata": {"id": "aDoBJxbA_Zct"}, "source": "Agora, chame a fun\u00e7\u00e3o `replace_wrong_genres()` e passe argumentos apropriados para que ela limpe duplicados impl\u00edcitos (`hip`, `hop` e `hip-hop`) substituindo-os por `hiphop`:"}, {"cell_type": "code", "execution_count": 29, "metadata": {"id": "YN5i2hpmSo09", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n 'unknown' 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock'\n 'latin' 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental'\n 'rusrock' 'dnb' 't\u00fcrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n 'disco' 'religious' 'drum' 'extrememetal' 't\u00fcrk\u00e7e' 'experimental' 'easy'\n 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n 'stonerrock' 'industrial' 'funk' 'middle' 'vari\u00e9t\u00e9' 'other' 'adult'\n 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n 'africa' 'audiobook' 'jewish' 's\u00e4ngerportrait' 'deutschrock' 'eastern'\n 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n 'brazilian' '\u00ef\u00ee\u00ef' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n 'synthpop' 'rave' 'franz\u00f6sisch' 'quebecois' 'speech' 'soulful' 'jam'\n 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n 'ax\u00e9' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forr\u00f3' 'dirty'\n 'regional']\n"}], "source": "\n\n\ndef replace_wrong_genres(wrong_genres, correct_genre):\n    for genre in wrong_genres:\n        df['genre'] = df['genre'].replace(genre, correct_genre)\n\n\nwrong_genres = ['hip', 'hop', 'hip-hop']\n\n\ncorrect_genre = 'hiphop'\n\n\nreplace_wrong_genres(wrong_genres, correct_genre)\n\n\nprint(df['genre'].unique()) \n# removendo duplicados impl\u00edcitos\n"}, {"cell_type": "markdown", "metadata": {"id": "zQKF16_RG15m"}, "source": "Certifique-se que os nomes duplicados foram removidos. Imprima a lista de valores \u00fanicos da coluna `'genre'` mais uma vez:"}, {"cell_type": "code", "execution_count": 30, "metadata": {"id": "wvixALnFG15m", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Valores \u00fanicos na coluna 'genre' ap\u00f3s a substitui\u00e7\u00e3o:\n['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n 'unknown' 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock'\n 'latin' 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental'\n 'rusrock' 'dnb' 't\u00fcrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n 'disco' 'religious' 'drum' 'extrememetal' 't\u00fcrk\u00e7e' 'experimental' 'easy'\n 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n 'stonerrock' 'industrial' 'funk' 'middle' 'vari\u00e9t\u00e9' 'other' 'adult'\n 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n 'africa' 'audiobook' 'jewish' 's\u00e4ngerportrait' 'deutschrock' 'eastern'\n 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n 'brazilian' '\u00ef\u00ee\u00ef' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n 'synthpop' 'rave' 'franz\u00f6sisch' 'quebecois' 'speech' 'soulful' 'jam'\n 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n 'ax\u00e9' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forr\u00f3' 'dirty'\n 'regional']\n"}], "source": "\n\ndef replace_wrong_genres(wrong_genres, correct_genre):\n    for genre in wrong_genres:\n        df['genre'] = df['genre'].replace(genre, correct_genre)\n\n\nwrong_genres = ['hip', 'hop', 'hip-hop']\n\n\ncorrect_genre = 'hiphop'\n\n\nreplace_wrong_genres(wrong_genres, correct_genre)\n\n\nprint(\"Valores \u00fanicos na coluna 'genre' ap\u00f3s a substitui\u00e7\u00e3o:\")\nprint(df['genre'].unique())# verificando valores duplicados\n"}, {"cell_type": "markdown", "metadata": {"id": "ALgNbvF3VtPA"}, "source": "[Voltar ao \u00cdndice](#back)"}, {"cell_type": "markdown", "metadata": {"id": "jz6a9-7HQUDd"}, "source": "### Suas observa\u00e7\u00f5es <a id='data_preprocessing_conclusions'></a>\n\n` Descreva brevemente o que voc\u00ea reparou ao analisar duplicados, bem como a abordagem que usou para elimin\u00e1-los e os resultados que alcan\u00e7ou.`\n\nHouve alguns erros na coluna HIP-POP pela forma escrita que acabou atrapalhando a pesquisa.\nCriei uma fun\u00e7\u00e3o para percorrer a lista de e detectar as formas variaveis de escrita para o mesmo g\u00eanero.\nCorre\u00e7\u00e3o da coluna com nomes vari\u00e1veis para um mesmo g\u00eanero"}, {"cell_type": "markdown", "metadata": {"id": "eK1es74rVujj"}, "source": "[Voltar ao \u00cdndice](#back)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<strong>Coment\u00e1rio do revisor v2</strong>\n\nBom trabalho com os duplicados impl\u00edcitos e expl\u00edcitos\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "WttZHXH0SqKk"}, "source": "## Etapa 3. Teste da hip\u00f3tese <a id='hypothesis'></a>"}, {"cell_type": "markdown", "metadata": {"id": "Im936VVi_Zcu"}, "source": "### Hip\u00f3tese: compara\u00e7\u00e3o do comportamento dos usu\u00e1rios nas duas cidades <a id='activity'></a>"}, {"cell_type": "markdown", "metadata": {"id": "nwt_MuaL_Zcu"}, "source": "A hip\u00f3tese afirma que existem diferen\u00e7as no consumo de m\u00fasica pelos usu\u00e1rios em Springfield e em Shelbyville. Para testar a hip\u00f3tese, use os dados dos tr\u00eas dias da semana: segunda-feira (Monday), quarta-feira (Wednesday) e sexta-feira (Friday).\n\n* Agrupe os usu\u00e1rios por cidade.\n* Compare o n\u00famero de m\u00fasicas tocadas por cada grupo na segunda, quarta e sexta.\n"}, {"cell_type": "markdown", "metadata": {"id": "8Dw_YMmT_Zcu"}, "source": "Execute cada c\u00e1lculo separadamente.\n\nO primeiro passo \u00e9 avaliar a atividade dos usu\u00e1rios em cada cidade. N\u00e3o se esque\u00e7a das etapas \"divis\u00e3o-aplica\u00e7\u00e3o-combina\u00e7\u00e3o\" sobre as quais falamos anteriormente na li\u00e7\u00e3o. Agora seu objetivo \u00e9 agrupar os dados por cidade, aplicar o m\u00e9todo de contagem apropriado durante a etapa de aplica\u00e7\u00e3o e ent\u00e3o encontrar o n\u00famero de m\u00fasicas tocadas por cada grupo, especificando a coluna para a qual voc\u00ea quer obter a contagem.\n\nVeja um exemplo de como o resultado final deve ser:\n`df.groupby(by='....')['column'].method()` Execute cada c\u00e1lculo separadamente.\n\nPara avaliar a atividade dos usu\u00e1rios em cada cidade, agrupe os dados por cidade e encontre o n\u00famero de m\u00fasicas reproduzidas em cada grupo.\n\n"}, {"cell_type": "code", "execution_count": 15, "metadata": {"id": "0_Qs96oh_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "  City       Day      \nShelbyville  Friday        6146\n             Monday        5820\n             Wednesday     7336\nSpringfield  Friday       16622\n             Monday       16286\n             Wednesday    11526\nName: Track, dtype: int64\n"}], "source": "\n\ndf_filtered = df[df['Day'].isin(['Monday', 'Wednesday', 'Friday'])]\n\n\ncount_music = df_filtered.groupby(['  City  ', 'Day'])['Track'].count()\n\n\nprint(count_music)# Contando as m\u00fasicas tocadas em cada cidade\n"}, {"cell_type": "markdown", "metadata": {"id": "t_Qx-3NewAnK"}, "source": "`Comente sobre suas observa\u00e7\u00f5es aqui`\n\nSpringfield tem mais ouvintes do que a outra cidade comparada.\nExiste um aumento de ouvintes na sexta- feira, isso pode ser pelo final de semana, ou engarrafamento ou outras quest\u00f5es que implicam em mais tempo ocioso para ouvir m\u00fasicas.\nEssa diferen\u00e7a de ouvintes pode estar diretamente ligada ao tamanho da popula\u00e7\u00e3o.\n"}, {"cell_type": "markdown", "metadata": {"id": "dzli3w8o_Zcu"}, "source": "Agora vamos agrupar os dados por dia da semana e encontrar a quantidade de m\u00fasicas tocadas na segunda, quarta e sexta-feira. Use a mesma abordagem que antes, mas agora precisamos agrupar os dados de uma forma diferente.\n"}, {"cell_type": "code", "execution_count": 21, "metadata": {"id": "uZMKjiJz_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Day\nFriday       23149\nMonday       22697\nWednesday    19233\nName: Track, dtype: int64\n"}], "source": "\ndf_filtered = df[df['Day'].isin(['Monday', 'Wednesday', 'Friday'])]\n\n\ncount_music_by_day = df_filtered.groupby('Day')['Track'].count()\n\n\nprint(count_music_by_day)# Calculando as m\u00fasicas escutadas em cada um desses tr\u00eas dias\n"}, {"cell_type": "markdown", "metadata": {"id": "cC2tNrlL_Zcu"}, "source": "`Comente sobre suas observa\u00e7\u00f5es aqui`\n\nExiste um aumento de ouvintes na sexta- feira, isso pode ser pelo final de semana, ou engarrafamento ou outras quest\u00f5es que implicam em mais tempo ocioso para ouvir m\u00fasicas.\nEssa diferen\u00e7a de ouvintes pode estar diretamente ligada ao tamanho da popula\u00e7\u00e3o."}, {"cell_type": "markdown", "metadata": {"id": "POzs8bGa_Zcu"}, "source": "Voc\u00ea acabou de aprender como contar entradas agrupando-as por cidade ou por dia. E agora voc\u00ea precisa escrever uma fun\u00e7\u00e3o que possa contar entradas simultaneamente com base em ambos os crit\u00e9rios.\n\nCrie a fun\u00e7\u00e3o `number_tracks()` para calcular o n\u00famero de m\u00fasicas tocadas em um determinado dia **e** em uma determinada cidade. A fun\u00e7\u00e3o deve aceitar dois par\u00e2metros:\n\n- `day`: um dia da semana pelo qual precisamos filtrar os dados. Por exemplo, `'Monday'`.\n- `city`: uma cidade pela qual precisamos filtrar os dados. Por exemplo, `'Springfield'`.\n\nDentro da fun\u00e7\u00e3o, voc\u00ea vai aplicar uma filtragem consecutiva com indexa\u00e7\u00e3o l\u00f3gica.\n\nPrimeiro, filtre os dados por dia e ent\u00e3o filtre a tabela resultante por cidade.\n\nDepois de filtrar os dados usando os dois crit\u00e9rios, conte o n\u00famero de valores na coluna 'user_id' da tabela resultante. O resultado da contagem representar\u00e1 o n\u00famero de entradas que voc\u00ea quer encontrar. Armazene o resultado em uma nova vari\u00e1vel e imprima-o."}, {"cell_type": "code", "execution_count": 26, "metadata": {"id": "Nz3GdQB1_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "16715\n6259\n"}], "source": "\n\ndef number_tracks(Day, City):\n    filtered_data = df[df['Day'] == Day]# Declare a fun\u00e7\u00e3o number_tracks() com dois par\u00e2metros: day= e city=.\n\n    filtered_data = filtered_data[filtered_data['  City  '] == City]# Armazene as linhas do DataFrame em que o valor na coluna 'day' \u00e9 igual ao par\u00e2metro day=\n\n    filtered_data = filtered_data[filtered_data['  City  '] == City]# Filtre as linhas em que o valor na coluna 'city' \u00e9 igual ao par\u00e2metro city=\n\n    count = filtered_data['user_id'].count()# Extraia a coluna 'user_id' da tabela filtrada e aplique o m\u00e9todo count()\n\n    return count # Retorne o n\u00famero dos valores da coluna 'user_id'\n\nprint(number_tracks('Monday', 'Springfield'))  \nprint(number_tracks('Friday', 'Shelbyville'))"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-danger\">\n<strong>Coment\u00e1rio do revisor v2</strong>\n\nN\u00e3o deve haver re-importa\u00e7\u00e3o dos dados nessa sess\u00e3o.\n    \nNote que n\u00e3o deve haver nenhum dia x cidade com zero erprodu\u00e7\u00f5es.\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "ytf7xFrFJQ2r"}, "source": "Chame a fun\u00e7\u00e3o `number_tracks()` seis vezes, mudando os valores dos par\u00e2metros, para que voc\u00ea possa recuperar os dados de ambas as cidades para cada um dos tr\u00eas dias."}, {"cell_type": "code", "execution_count": 45, "metadata": {"id": "rJcRATNQ_Zcu", "trusted": true}, "outputs": [], "source": "\n\ndef number_tracks(Day, City):\n    filtered_data = df[df['Day'] == Day]\n    filtered_data = filtered_data[filtered_data['  City  '] == City]\n    count = filtered_data['user_id'].count()\n    return count\n\n# a quantidade de m\u00fasicas tocadas em Springfield na segunda-feira\n"}, {"cell_type": "code", "execution_count": 40, "metadata": {"id": "hq_ncZ5T_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "5982\n"}], "source": "print(number_tracks('Monday', 'Shelbyville'))\n# a quantidade de m\u00fasicas tocadas em Shelbyville na segunda-feira\n"}, {"cell_type": "code", "execution_count": 41, "metadata": {"id": "_NTy2VPU_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "11755\n"}], "source": "print (number_tracks(\"Wednesday\",\"Springfield\"))# a quantidade de m\u00fasicas tocadas em Springfield na quarta-feira\n"}, {"cell_type": "code", "execution_count": 42, "metadata": {"id": "j2y3TAwo_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "0\n"}], "source": "print(number_tracks(\"Wesdnesday\",\"Shelbyville\"))# a quantidade de m\u00fasicas tocadas em Shelbyville na quarta-feira\n"}, {"cell_type": "code", "execution_count": 43, "metadata": {"id": "vYDw5u_K_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "16890\n"}], "source": "print(number_tracks(\"Friday\",\"Springfield\"))# a quantidade de m\u00fasicas tocadas em Springfield na sexta-feira\n"}, {"cell_type": "code", "execution_count": 44, "metadata": {"id": "8_yzFtW3_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "6259\n"}], "source": "print(number_tracks(\"Friday\",\"Shelbyville\"))# a quantidade de m\u00fasicas tocadas em Shelbyville na sexta-feira\n"}, {"cell_type": "markdown", "metadata": {"id": "-EgPIHYu_Zcu"}, "source": "**Conclus\u00f5es**\n\n`Comente sobre se a terceira hip\u00f3tese est\u00e1 correta ou deve ser rejeitada. Explique seu racioc\u00ednio.`\n\nAcredito que o numero populacional ocasiona o aumento significativo de Springfield quando comparada a Shelbyville.\nConforme a dica do revisor, existe um crescimento de ouvintes para Springfiel, enquanto Shelbyville mostra uma ruptura na quarta-feira"}, {"cell_type": "markdown", "metadata": {"id": "p7nFQajCVw5B"}, "source": "[Voltar ao \u00cdndice](#back)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-danger\">\n<strong>Coment\u00e1rio do revisor v3</strong>\n\n    \nEssa \u00faltima sess\u00e3o precisa de alguns ajustes por conta do nome das colunas.    \n\nVoc\u00ea passou por pontos importantes na an\u00e1lise da hip\u00f3tese, mas existe mais uma dimens\u00e3o para ser considerada que \u00e9 s\u00e3o os movimentos que as reprodu\u00e7\u00f5es tem em cada uma das cidades.\n    \nEm Springville por exemplo vemos que a segunda e a sexta s\u00e3o pr\u00f3ximas mas as quartas representam um vale. Como isso se compara com o que temos em Shelbyville?\n    \nDadas as diferen\u00e7as no # de reprodu\u00e7\u00f5es, essa an\u00e1lise passa a ser extremamente relevante.\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "ykKQ0N65_Zcv"}, "source": "# Conclus\u00f5es <a id='end'></a>"}, {"cell_type": "markdown", "metadata": {"id": "tjUwbHb3_Zcv"}, "source": "`Resuma suas conclus\u00f5es sobre a hip\u00f3tese aqui`\n\n\nHip\u00f3tese Principal: \n\nA maior popula\u00e7\u00e3o de Springfield parece ser um fator importante que justifica o aumento da contagem de usu\u00e1rios em rela\u00e7\u00e3o a Shelbyville. A quantidade maior de pessoas pode resultar em mais intera\u00e7\u00f5es ou engajamento com a plataforma analisada.\n\nVari\u00e1veis Impl\u00edcitas:\n\nEmbora o n\u00famero populacional seja um fator significativo, outras vari\u00e1veis podem estar influenciando os resultados. Aspectos como o tr\u00e2nsito e o tempo livre de uma popula\u00e7\u00e3o mais jovem (possivelmente mais conectada ou engajada) podem ser fatores adicionais que contribuem para as diferen\u00e7as observadas.\n\nImport\u00e2ncia de Investigar Vari\u00e1veis Externas: \n\nA conclus\u00e3o de que fatores externos, como condi\u00e7\u00f5es sociais ou comportamentais (ex. mobilidade e estrutura demogr\u00e1fica), podem afetar a contagem de usu\u00e1rios \u00e9 v\u00e1lida. \u00c9 importante considerar essas vari\u00e1veis ao formar uma conclus\u00e3o definitiva.\n\n"}, {"cell_type": "markdown", "metadata": {"id": "azLHu64yOIp7"}, "source": "### Importante\nEm projetos de pesquisas reais, o teste estat\u00edstico de hip\u00f3teses \u00e9 mais preciso e quantitativo. Observe tamb\u00e9m que conclus\u00f5es sobre uma cidade inteira nem sempre podem ser tiradas a partir de dados de apenas uma fonte.\n\nVoc\u00ea aprender\u00e1 mais sobre testes de hip\u00f3teses no sprint sobre a an\u00e1lise estat\u00edstica de dados."}, {"cell_type": "markdown", "metadata": {"id": "Ju4AHDSgV1FE"}, "source": "[Voltar ao \u00cdndice](#back)"}], "metadata": {"ExecuteTimeLog": [{"duration": 327, "start_time": "2025-04-05T22:42:43.311Z"}, {"duration": 5, "start_time": "2025-04-05T22:44:23.801Z"}, {"duration": 188, "start_time": "2025-04-05T22:44:36.385Z"}, {"duration": 117, "start_time": "2025-04-05T22:45:26.713Z"}, {"duration": 7, "start_time": "2025-04-05T22:53:10.236Z"}, {"duration": 22, "start_time": "2025-04-05T22:57:18.375Z"}, {"duration": 2, "start_time": "2025-04-05T22:58:54.934Z"}, {"duration": 2, "start_time": "2025-04-05T22:58:59.403Z"}, {"duration": 12, "start_time": "2025-04-05T23:10:36.879Z"}, {"duration": 344, "start_time": "2025-04-05T23:11:35.609Z"}, {"duration": 4, "start_time": "2025-04-05T23:12:39.289Z"}, {"duration": 3, "start_time": "2025-04-05T23:22:40.286Z"}, {"duration": 15, "start_time": "2025-04-05T23:24:34.032Z"}, {"duration": 22, "start_time": "2025-04-05T23:25:38.485Z"}, {"duration": 11, "start_time": "2025-04-05T23:26:00.624Z"}, {"duration": 11, "start_time": "2025-04-05T23:26:12.051Z"}, {"duration": 74, "start_time": "2025-04-05T23:27:17.231Z"}, {"duration": 4, "start_time": "2025-04-05T23:28:42.669Z"}, {"duration": 7, "start_time": "2025-04-05T23:31:47.184Z"}, {"duration": 3, "start_time": "2025-04-05T23:32:18.000Z"}, {"duration": 2, "start_time": "2025-04-05T23:32:48.298Z"}, {"duration": 95, "start_time": "2025-04-05T23:32:54.361Z"}, {"duration": 3, "start_time": "2025-04-05T23:33:55.767Z"}, {"duration": 8, "start_time": "2025-04-05T23:34:12.448Z"}, {"duration": 3, "start_time": "2025-04-05T23:34:17.519Z"}, {"duration": 8, "start_time": "2025-04-05T23:34:23.676Z"}, {"duration": 7, "start_time": "2025-04-05T23:34:27.282Z"}, {"duration": 5, "start_time": "2025-04-05T23:34:35.781Z"}, {"duration": 3, "start_time": "2025-04-05T23:34:40.544Z"}, {"duration": 7, "start_time": "2025-04-05T23:34:52.148Z"}, {"duration": 3, "start_time": "2025-04-05T23:34:56.230Z"}, {"duration": 6, "start_time": "2025-04-05T23:41:11.726Z"}, {"duration": 3, "start_time": "2025-04-05T23:41:15.876Z"}, {"duration": 16, "start_time": "2025-04-05T23:42:26.176Z"}, {"duration": 405, "start_time": "2025-04-05T23:54:50.649Z"}, {"duration": 3, "start_time": "2025-04-05T23:56:29.899Z"}, {"duration": 11, "start_time": "2025-04-05T23:56:56.631Z"}, {"duration": 19, "start_time": "2025-04-05T23:57:55.764Z"}, {"duration": 3, "start_time": "2025-04-06T00:02:43.196Z"}, {"duration": 43, "start_time": "2025-04-06T00:02:53.149Z"}, {"duration": 44, "start_time": "2025-04-06T00:04:03.629Z"}, {"duration": 37, "start_time": "2025-04-06T00:04:29.446Z"}, {"duration": 62, "start_time": "2025-04-06T00:05:26.979Z"}, {"duration": 58, "start_time": "2025-04-06T00:06:02.377Z"}, {"duration": 51, "start_time": "2025-04-06T00:06:17.179Z"}, {"duration": 61, "start_time": "2025-04-06T00:06:51.310Z"}, {"duration": 45, "start_time": "2025-04-06T00:07:10.419Z"}, {"duration": 93, "start_time": "2025-04-06T00:07:44.210Z"}, {"duration": 8, "start_time": "2025-04-06T00:08:18.225Z"}, {"duration": 7, "start_time": "2025-04-06T00:08:30.142Z"}, {"duration": 11, "start_time": "2025-04-06T00:08:46.221Z"}, {"duration": 21, "start_time": "2025-04-06T00:09:27.454Z"}, {"duration": 17, "start_time": "2025-04-06T00:09:53.706Z"}, {"duration": 14, "start_time": "2025-04-06T00:10:27.470Z"}, {"duration": 4, "start_time": "2025-04-06T00:15:38.593Z"}, {"duration": 6, "start_time": "2025-04-06T00:16:00.958Z"}, {"duration": 128, "start_time": "2025-04-06T00:17:00.104Z"}, {"duration": 168, "start_time": "2025-04-06T00:20:23.792Z"}, {"duration": 143, "start_time": "2025-04-06T00:21:55.852Z"}, {"duration": 123, "start_time": "2025-04-06T00:24:39.804Z"}, {"duration": 104, "start_time": "2025-04-06T00:25:09.299Z"}, {"duration": 6, "start_time": "2025-04-06T00:26:31.089Z"}, {"duration": 97, "start_time": "2025-04-06T00:26:43.639Z"}, {"duration": 118, "start_time": "2025-04-06T00:27:19.000Z"}, {"duration": 90, "start_time": "2025-04-06T00:28:05.402Z"}, {"duration": 119, "start_time": "2025-04-06T00:30:52.835Z"}, {"duration": 106, "start_time": "2025-04-06T00:32:52.684Z"}, {"duration": 136, "start_time": "2025-04-06T00:34:47.687Z"}, {"duration": 125, "start_time": "2025-04-06T00:35:01.135Z"}, {"duration": 121, "start_time": "2025-04-06T00:35:25.390Z"}, {"duration": 86, "start_time": "2025-04-06T00:36:35.149Z"}, {"duration": 115, "start_time": "2025-04-06T00:38:11.600Z"}, {"duration": 122, "start_time": "2025-04-06T00:38:39.898Z"}, {"duration": 101, "start_time": "2025-04-06T00:38:43.115Z"}, {"duration": 108, "start_time": "2025-04-06T00:39:11.444Z"}, {"duration": 127, "start_time": "2025-04-06T00:40:14.165Z"}, {"duration": 102, "start_time": "2025-04-06T00:42:07.362Z"}, {"duration": 103, "start_time": "2025-04-06T00:43:15.558Z"}, {"duration": 101, "start_time": "2025-04-06T00:49:05.239Z"}, {"duration": 107, "start_time": "2025-04-06T00:49:21.795Z"}, {"duration": 100, "start_time": "2025-04-06T00:50:16.160Z"}, {"duration": 109, "start_time": "2025-04-06T00:51:16.291Z"}, {"duration": 117, "start_time": "2025-04-06T00:53:19.821Z"}, {"duration": 109, "start_time": "2025-04-06T00:53:38.192Z"}, {"duration": 102, "start_time": "2025-04-06T00:56:19.171Z"}, {"duration": 100, "start_time": "2025-04-06T01:00:19.504Z"}, {"duration": 132, "start_time": "2025-04-06T01:07:11.200Z"}, {"duration": 132, "start_time": "2025-04-06T01:07:29.667Z"}, {"duration": 243, "start_time": "2025-04-06T01:07:52.234Z"}, {"duration": 296, "start_time": "2025-04-06T01:08:13.018Z"}, {"duration": 108, "start_time": "2025-04-06T01:08:27.181Z"}, {"duration": 102, "start_time": "2025-04-06T01:16:55.575Z"}, {"duration": 136, "start_time": "2025-04-06T01:23:38.892Z"}, {"duration": 101, "start_time": "2025-04-06T01:24:04.309Z"}, {"duration": 112, "start_time": "2025-04-06T01:24:41.307Z"}, {"duration": 138, "start_time": "2025-04-06T01:25:27.109Z"}, {"duration": 146, "start_time": "2025-04-06T01:25:39.475Z"}, {"duration": 141, "start_time": "2025-04-06T01:25:59.181Z"}, {"duration": 453, "start_time": "2025-04-06T23:07:55.947Z"}, {"duration": 95, "start_time": "2025-04-06T23:08:00.576Z"}, {"duration": 5, "start_time": "2025-04-06T23:08:37.211Z"}, {"duration": 99, "start_time": "2025-04-06T23:08:54.943Z"}, {"duration": 104, "start_time": "2025-04-06T23:10:40.927Z"}, {"duration": 98, "start_time": "2025-04-06T23:10:55.578Z"}, {"duration": 108, "start_time": "2025-04-06T23:11:39.494Z"}, {"duration": 120, "start_time": "2025-04-06T23:12:58.688Z"}, {"duration": 116, "start_time": "2025-04-06T23:13:27.521Z"}, {"duration": 118, "start_time": "2025-04-06T23:14:28.740Z"}, {"duration": 133, "start_time": "2025-04-06T23:15:03.609Z"}, {"duration": 130, "start_time": "2025-04-06T23:15:10.725Z"}, {"duration": 128, "start_time": "2025-04-06T23:15:15.076Z"}, {"duration": 110, "start_time": "2025-04-06T23:16:07.209Z"}, {"duration": 110, "start_time": "2025-04-06T23:16:13.170Z"}, {"duration": 135, "start_time": "2025-04-06T23:16:23.626Z"}, {"duration": 51, "start_time": "2025-04-06T23:16:38.091Z"}, {"duration": 109, "start_time": "2025-04-06T23:16:59.004Z"}, {"duration": 114, "start_time": "2025-04-06T23:30:15.052Z"}, {"duration": 657, "start_time": "2025-04-06T23:36:33.898Z"}, {"duration": 145, "start_time": "2025-04-06T23:37:36.809Z"}, {"duration": 145, "start_time": "2025-04-06T23:37:57.099Z"}, {"duration": 162, "start_time": "2025-04-06T23:38:17.920Z"}, {"duration": 149, "start_time": "2025-04-06T23:38:50.046Z"}, {"duration": 156, "start_time": "2025-04-06T23:38:57.359Z"}, {"duration": 151, "start_time": "2025-04-06T23:39:27.647Z"}, {"duration": 118, "start_time": "2025-04-06T23:39:44.031Z"}, {"duration": 147, "start_time": "2025-04-06T23:44:20.930Z"}, {"duration": 106, "start_time": "2025-04-06T23:44:45.548Z"}, {"duration": 13, "start_time": "2025-04-06T23:45:31.347Z"}, {"duration": 12, "start_time": "2025-04-06T23:47:04.247Z"}, {"duration": 7, "start_time": "2025-04-06T23:48:20.445Z"}, {"duration": 13, "start_time": "2025-04-06T23:49:02.861Z"}, {"duration": 12, "start_time": "2025-04-06T23:49:46.873Z"}, {"duration": 12, "start_time": "2025-04-06T23:49:55.778Z"}, {"duration": 11, "start_time": "2025-04-06T23:50:11.096Z"}, {"duration": 13, "start_time": "2025-04-06T23:50:34.527Z"}, {"duration": 155, "start_time": "2025-04-08T22:17:40.851Z"}, {"duration": 12, "start_time": "2025-04-08T22:17:57.750Z"}, {"duration": 14, "start_time": "2025-04-08T22:22:09.753Z"}, {"duration": 11, "start_time": "2025-04-08T22:23:03.726Z"}, {"duration": 329, "start_time": "2025-04-08T22:23:18.764Z"}, {"duration": 13, "start_time": "2025-04-08T22:23:32.464Z"}, {"duration": 110, "start_time": "2025-04-08T22:26:06.696Z"}, {"duration": 93, "start_time": "2025-04-08T22:26:41.229Z"}, {"duration": 3, "start_time": "2025-04-08T22:27:24.579Z"}, {"duration": 95, "start_time": "2025-04-08T22:28:29.460Z"}, {"duration": 168, "start_time": "2025-04-09T07:21:16.013Z"}, {"duration": 11, "start_time": "2025-04-09T07:22:15.094Z"}, {"duration": 12, "start_time": "2025-04-09T07:22:23.327Z"}, {"duration": 13, "start_time": "2025-04-09T07:25:35.756Z"}, {"duration": 13, "start_time": "2025-04-09T07:25:48.381Z"}, {"duration": 12, "start_time": "2025-04-09T07:26:05.323Z"}, {"duration": 12, "start_time": "2025-04-09T07:26:18.085Z"}, {"duration": 31, "start_time": "2025-04-09T07:26:54.159Z"}, {"duration": 11, "start_time": "2025-04-09T07:26:59.171Z"}, {"duration": 12, "start_time": "2025-04-09T07:28:30.637Z"}, {"duration": 11, "start_time": "2025-04-09T07:30:01.621Z"}, {"duration": 13, "start_time": "2025-04-09T07:30:09.777Z"}, {"duration": 11, "start_time": "2025-04-09T07:30:59.123Z"}, {"duration": 281, "start_time": "2025-04-09T07:32:04.784Z"}, {"duration": 121, "start_time": "2025-04-09T07:32:07.804Z"}, {"duration": 7, "start_time": "2025-04-09T07:32:11.813Z"}, {"duration": 11, "start_time": "2025-04-09T07:32:30.207Z"}, {"duration": 51, "start_time": "2025-04-09T07:33:01.240Z"}, {"duration": 44, "start_time": "2025-04-09T07:35:25.456Z"}, {"duration": 400, "start_time": "2025-04-09T07:36:49.374Z"}, {"duration": 49, "start_time": "2025-04-09T07:37:56.980Z"}, {"duration": 49, "start_time": "2025-04-09T07:38:25.466Z"}, {"duration": 51, "start_time": "2025-04-09T07:38:50.062Z"}, {"duration": 14, "start_time": "2025-04-09T07:39:16.837Z"}, {"duration": 26, "start_time": "2025-04-09T07:39:43.437Z"}, {"duration": 52, "start_time": "2025-04-09T07:39:56.402Z"}, {"duration": 50, "start_time": "2025-04-09T07:40:19.437Z"}, {"duration": 4, "start_time": "2025-04-09T07:40:49.002Z"}, {"duration": 3, "start_time": "2025-04-09T07:41:04.453Z"}, {"duration": 10, "start_time": "2025-04-09T07:41:17.284Z"}, {"duration": 20, "start_time": "2025-04-09T07:41:30.339Z"}, {"duration": 25, "start_time": "2025-04-09T07:41:46.385Z"}, {"duration": 91, "start_time": "2025-04-09T07:42:31.709Z"}, {"duration": 45, "start_time": "2025-04-09T07:42:58.817Z"}, {"duration": 21, "start_time": "2025-04-09T07:43:29.132Z"}, {"duration": 49, "start_time": "2025-04-09T07:43:46.352Z"}, {"duration": 25, "start_time": "2025-04-09T07:44:11.269Z"}, {"duration": 28, "start_time": "2025-04-09T07:44:35.151Z"}, {"duration": 24, "start_time": "2025-04-09T07:44:43.399Z"}, {"duration": 47, "start_time": "2025-04-09T07:45:42.117Z"}, {"duration": 19, "start_time": "2025-04-09T07:45:52.763Z"}, {"duration": 396, "start_time": "2025-04-09T11:50:41.991Z"}, {"duration": 112, "start_time": "2025-04-09T11:50:42.390Z"}, {"duration": 8, "start_time": "2025-04-09T11:50:42.503Z"}, {"duration": 20, "start_time": "2025-04-09T11:50:42.512Z"}, {"duration": 3, "start_time": "2025-04-09T11:50:42.534Z"}, {"duration": 4, "start_time": "2025-04-09T11:50:42.539Z"}, {"duration": 2, "start_time": "2025-04-09T11:50:42.545Z"}, {"duration": 11, "start_time": "2025-04-09T11:50:42.549Z"}, {"duration": 4, "start_time": "2025-04-09T11:50:42.561Z"}, {"duration": 43, "start_time": "2025-04-09T11:50:42.566Z"}, {"duration": 2, "start_time": "2025-04-09T11:52:14.141Z"}, {"duration": 96, "start_time": "2025-04-09T11:52:14.145Z"}, {"duration": 5, "start_time": "2025-04-09T11:52:14.243Z"}, {"duration": 19, "start_time": "2025-04-09T11:52:14.250Z"}, {"duration": 3, "start_time": "2025-04-09T11:52:14.271Z"}, {"duration": 4, "start_time": "2025-04-09T11:52:14.275Z"}, {"duration": 3, "start_time": "2025-04-09T11:52:14.280Z"}, {"duration": 8, "start_time": "2025-04-09T11:52:14.308Z"}, {"duration": 2, "start_time": "2025-04-09T11:52:14.318Z"}, {"duration": 3, "start_time": "2025-04-09T11:52:14.322Z"}, {"duration": 18, "start_time": "2025-04-09T11:52:14.326Z"}, {"duration": 23, "start_time": "2025-04-09T11:52:14.346Z"}, {"duration": 42, "start_time": "2025-04-09T11:52:14.373Z"}, {"duration": 42, "start_time": "2025-04-09T11:52:14.416Z"}, {"duration": 59, "start_time": "2025-04-09T11:52:14.461Z"}, {"duration": 41, "start_time": "2025-04-09T11:52:14.522Z"}, {"duration": 18, "start_time": "2025-04-09T11:52:14.565Z"}, {"duration": 32, "start_time": "2025-04-09T11:52:14.585Z"}, {"duration": 10, "start_time": "2025-04-09T11:52:14.619Z"}, {"duration": 11, "start_time": "2025-04-09T11:52:14.630Z"}, {"duration": 541, "start_time": "2025-04-09T11:52:14.643Z"}, {"duration": 0, "start_time": "2025-04-09T11:52:15.186Z"}, {"duration": 0, "start_time": "2025-04-09T11:52:15.187Z"}, {"duration": 0, "start_time": "2025-04-09T11:52:15.189Z"}, {"duration": 0, "start_time": "2025-04-09T11:52:15.190Z"}, {"duration": 0, "start_time": "2025-04-09T11:52:15.192Z"}, {"duration": 1, "start_time": "2025-04-09T11:52:15.193Z"}, {"duration": 0, "start_time": "2025-04-09T11:52:15.209Z"}, {"duration": 0, "start_time": "2025-04-09T11:52:15.210Z"}, {"duration": 38, "start_time": "2025-04-09T11:52:25.612Z"}, {"duration": 53, "start_time": "2025-04-09T11:52:27.951Z"}, {"duration": 19, "start_time": "2025-04-09T11:52:29.017Z"}, {"duration": 16, "start_time": "2025-04-09T11:52:29.283Z"}, {"duration": 16, "start_time": "2025-04-09T11:52:29.625Z"}, {"duration": 17, "start_time": "2025-04-09T11:52:29.931Z"}, {"duration": 16, "start_time": "2025-04-09T11:52:30.131Z"}, {"duration": 16, "start_time": "2025-04-09T11:52:30.303Z"}, {"duration": 180, "start_time": "2025-04-09T21:24:20.440Z"}, {"duration": 17, "start_time": "2025-04-09T21:24:26.072Z"}, {"duration": 320, "start_time": "2025-04-09T21:25:26.366Z"}, {"duration": 114, "start_time": "2025-04-09T21:25:30.563Z"}, {"duration": 8, "start_time": "2025-04-09T21:25:33.363Z"}, {"duration": 13, "start_time": "2025-04-09T21:25:54.870Z"}, {"duration": 3, "start_time": "2025-04-09T21:26:00.383Z"}, {"duration": 3, "start_time": "2025-04-09T21:26:04.583Z"}, {"duration": 37, "start_time": "2025-04-09T21:27:09.773Z"}, {"duration": 13, "start_time": "2025-04-09T21:27:15.401Z"}, {"duration": 401, "start_time": "2025-04-09T21:27:39.952Z"}, {"duration": 40, "start_time": "2025-04-09T21:27:45.816Z"}, {"duration": 42, "start_time": "2025-04-09T21:28:29.751Z"}, {"duration": 20, "start_time": "2025-04-09T21:29:01.268Z"}, {"duration": 20, "start_time": "2025-04-09T21:29:37.867Z"}, {"duration": 15, "start_time": "2025-04-09T21:29:45.420Z"}, {"duration": 49, "start_time": "2025-04-09T21:30:31.386Z"}, {"duration": 29, "start_time": "2025-04-09T21:31:12.631Z"}, {"duration": 19, "start_time": "2025-04-09T21:31:20.978Z"}, {"duration": 26, "start_time": "2025-04-09T21:31:31.015Z"}, {"duration": 16, "start_time": "2025-04-09T21:32:20.731Z"}, {"duration": 59, "start_time": "2025-04-09T21:32:59.665Z"}, {"duration": 23, "start_time": "2025-04-09T21:33:21.649Z"}, {"duration": 24, "start_time": "2025-04-09T21:33:53.815Z"}, {"duration": 31, "start_time": "2025-04-09T21:34:06.953Z"}, {"duration": 29, "start_time": "2025-04-09T21:34:21.064Z"}, {"duration": 15, "start_time": "2025-04-09T21:34:58.151Z"}, {"duration": 14, "start_time": "2025-04-09T21:35:17.629Z"}, {"duration": 13, "start_time": "2025-04-09T21:35:22.759Z"}, {"duration": 13, "start_time": "2025-04-09T21:36:00.187Z"}, {"duration": 12, "start_time": "2025-04-09T21:36:06.281Z"}, {"duration": 7, "start_time": "2025-04-09T21:36:08.975Z"}, {"duration": 14, "start_time": "2025-04-09T21:36:11.579Z"}, {"duration": 15, "start_time": "2025-04-09T21:37:29.208Z"}, {"duration": 15, "start_time": "2025-04-09T21:37:59.178Z"}, {"duration": 14, "start_time": "2025-04-09T21:38:07.231Z"}, {"duration": 13, "start_time": "2025-04-09T21:38:10.161Z"}, {"duration": 14, "start_time": "2025-04-09T21:38:13.130Z"}, {"duration": 3, "start_time": "2025-04-09T21:40:12.191Z"}, {"duration": 14, "start_time": "2025-04-09T21:40:16.228Z"}, {"duration": 13, "start_time": "2025-04-09T21:40:16.944Z"}, {"duration": 7, "start_time": "2025-04-09T21:40:17.636Z"}, {"duration": 14, "start_time": "2025-04-09T21:40:18.298Z"}, {"duration": 12, "start_time": "2025-04-09T21:40:19.211Z"}, {"duration": 3, "start_time": "2025-04-09T21:43:38.593Z"}], "colab": {"collapsed_sections": ["E0vqbgi9ay0H", "VUC88oWjTJw2"], "provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 1}